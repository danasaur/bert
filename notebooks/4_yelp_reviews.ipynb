{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Yelp Reviews 1-5 stars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "!pip install torch\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yelp_review_full (/Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef92728e553847a18181c7f501877506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Load in the data\n",
    "dataset = load_dataset(\"yelp_review_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yelp_review_full (/Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167bfa0a20b54f7da2f55f0b36dc3c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-2403bacf86757b14.arrow and /Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-b05e24212690dea3.arrow\n",
      "Loading cached processed dataset at /Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-7df40f0f950cde94.arrow\n",
      "Loading cached processed dataset at /Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-9e189bd0c6edb59c.arrow\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/d/miniforge3/envs/bert/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5873839d38442b93dc3ed9ccec9e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2817f5c33c4448c8f49df71bf0d1e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6163889169692993, 'eval_accuracy': 0.3, 'eval_runtime': 1.5651, 'eval_samples_per_second': 12.779, 'eval_steps_per_second': 1.917, 'epoch': 1.0}\n",
      "{'train_runtime': 31.0158, 'train_samples_per_second': 3.224, 'train_steps_per_second': 0.419, 'train_loss': 1.6369115389310396, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=1.6369115389310396, metrics={'train_runtime': 31.0158, 'train_samples_per_second': 3.224, 'train_steps_per_second': 0.419, 'train_loss': 1.6369115389310396, 'epoch': 1.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "# 2. down-sample the dataset so it takes less time to train a quick baseline  model\n",
    "dataset_small = dataset[\"train\"].train_test_split(train_size=100, test_size=20, seed=42, stratify_by_column=\"label\")\n",
    "\n",
    "# 3. Load the tokenizer and define the tokenization function\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 4. Tokenize our training and test data\n",
    "tokenized_datasets = dataset_small.map(tokenize_function, batched=True)\n",
    "\n",
    "# 5. Load in the pre-trained model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5)\n",
    "\n",
    "# 6. Define an evaluation metric\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# 7. Set up the Trainer\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", num_train_epochs=1)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 8. Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted 5 stars for review: This is a great restaurant!\n",
      "Model predicted 5 stars for review: This was overall a good experience, above average restaurant\n",
      "Model predicted 5 stars for review: This was an alright restaurant\n",
      "Model predicted 5 stars for review: This is a pretty bad restaurant. I might try again but I was disappointed\n",
      "Model predicted 5 stars for review: This is a terrible restaurant!\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return predicted_class_id\n",
    "\n",
    "review_5stars = \"This is a great restaurant!\"\n",
    "review_4stars = \"This was overall a good experience, above average restaurant\"\n",
    "review_3stars = \"This was an alright restaurant\"\n",
    "review_2stars = \"This is a pretty bad restaurant. I might try again but I was disappointed\"\n",
    "review_1stars = \"This is a terrible restaurant!\"\n",
    "\n",
    "reviews = [review_5stars, review_4stars, review_3stars, review_2stars, review_1stars]\n",
    "\n",
    "for review in reviews:\n",
    "    print(f\"Model predicted {predict(review)+1} stars for review: {review}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't run this!! But see that simply adding more data, same code, the accuracy improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afb92b3e13c4d25b9a18d7160111f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4995917aa0ab4a83b30e479588550f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8bede44a704ea483e1144849c814f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d/miniforge3/envs/bert/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef9baa277a64247ad6ba77cfb0cdb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942448719f344d82a308ae2ae0549f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0930134057998657, 'eval_accuracy': 0.525, 'eval_runtime': 15.3889, 'eval_samples_per_second': 12.996, 'eval_steps_per_second': 1.625, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058447ea5e2747b3bce3dc3e63ddc3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0063376426696777, 'eval_accuracy': 0.58, 'eval_runtime': 15.3839, 'eval_samples_per_second': 13.001, 'eval_steps_per_second': 1.625, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7600c83ff7477cb719767b3b6c38b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.015762448310852, 'eval_accuracy': 0.595, 'eval_runtime': 15.3847, 'eval_samples_per_second': 13.0, 'eval_steps_per_second': 1.625, 'epoch': 3.0}\n",
      "{'train_runtime': 745.9547, 'train_samples_per_second': 3.217, 'train_steps_per_second': 0.402, 'train_loss': 0.9802055867513021, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.9802055867513021, metrics={'train_runtime': 745.9547, 'train_samples_per_second': 3.217, 'train_steps_per_second': 0.402, 'train_loss': 0.9802055867513021, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%capture\n",
    "\n",
    "# 1. Load in the data\n",
    "dataset = load_from_disk(\"data/yelp_review_small/\")\n",
    "\n",
    "# 2. Load the tokenizer and define the tokenization function\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 3. Tokenize our training and test data\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 4. Load in the pre-trained model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5)\n",
    "\n",
    "# 5. Define an evaluation metric\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# 6. Set up the Trainer\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 7. Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted class 4 for review: This is a great restaurant!\n",
      "Model predicted class 3 for review: This was overall a good experience, above average restaurant\n",
      "Model predicted class 2 for review: This was an alright restaurant\n",
      "Model predicted class 1 for review: This is a pretty bad restaurant. I might try again but I was disappointed\n",
      "Model predicted class 0 for review: This is a terrible restaurant!\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return predicted_class_id\n",
    "\n",
    "review_5stars = \"This is a great restaurant!\"\n",
    "review_4stars = \"This was overall a good experience, above average restaurant\"\n",
    "review_3stars = \"This was an alright restaurant\"\n",
    "review_2stars = \"This is a pretty bad restaurant. I might try again but I was disappointed\"\n",
    "review_1stars = \"This is a terrible restaurant!\"\n",
    "\n",
    "reviews = [review_5stars, review_4stars, review_3stars, review_2stars, review_1stars]\n",
    "\n",
    "for review in reviews:\n",
    "    print(f\"Model predicted class {predict(review)} for review: {review}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pandas dataframe\n",
    "df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have been using this company for 11 months',\n",
       " '  Ryan would come out every other week and do what he needed to be done',\n",
       " ' Very little was required as I have desert landscaping and pretty much maintained it myself',\n",
       " '  Just needed blowing and general light cleanup',\n",
       " '  Ryan was very thorough']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1star = df[df['label'] == 0]\n",
    "sample = df_1star['text'].values[-1]\n",
    "sample.split(\".\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " 'NOT EVEN A CALL WHEN THEY CANNOT COME',\n",
       " '   \\\\n\\\\nSORRY RYAN, I WILL TAKE MY BUSINESS ELSEWHERE',\n",
       " '  AS A BUSINESS OWNER, YOU SHOULD KNOW BETTER!!!!']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.split(\".\")[-5:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate if default token length of 512 is appropriate for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-df99a9b687c288ec.arrow\n",
      "Loading cached processed dataset at /Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-0b490f4e793ed0b0.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    650000.000000\n",
       "mean        180.696091\n",
       "std         163.847267\n",
       "min           3.000000\n",
       "25%          71.000000\n",
       "50%         132.000000\n",
       "75%         236.000000\n",
       "max        2344.000000\n",
       "Name: input_ids, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") # uncased means lowercase\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"this time we won't truncate the examples so that we can evaluate the distribution of the number of tokens for our reviews\n",
    "    \"\"\"\n",
    "    # prior implementation we used for training: return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "# this time we are doing the full dataset!\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "train_df = pd.DataFrame(tokenized_datasets[\"train\"])\n",
    "train_df[\"input_ids\"].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"input_ids\"].apply(len).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"input_ids_token_length\"] = train_df[\"input_ids\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>input_ids_token_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614419</th>\n",
       "      <td>3</td>\n",
       "      <td>Pour le jour de l'an 2010, nous \\u00e9tions a ...</td>\n",
       "      <td>[101, 10364, 3393, 8183, 3126, 2139, 1048, 100...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546323</th>\n",
       "      <td>4</td>\n",
       "      <td>**Summary**\\n       - Best - I have to start b...</td>\n",
       "      <td>[101, 1008, 1008, 12654, 1008, 1008, 1032, 105...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466919</th>\n",
       "      <td>2</td>\n",
       "      <td>Torii @ Lavel, Quecec, Canada, \\u30ab\\u30ca\\u3...</td>\n",
       "      <td>[101, 23413, 2072, 1030, 2474, 15985, 1010, 10...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570102</th>\n",
       "      <td>4</td>\n",
       "      <td>WED, MARCH 27, 2013 // 12:00PM-2:00PM \\n      ...</td>\n",
       "      <td>[101, 21981, 1010, 2233, 2676, 1010, 2286, 101...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603624</th>\n",
       "      <td>1</td>\n",
       "      <td>Was hier rumsitzt kennt das Angebot, diese bun...</td>\n",
       "      <td>[101, 2001, 7632, 2121, 19379, 28032, 2480, 21...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text   \n",
       "614419      3  Pour le jour de l'an 2010, nous \\u00e9tions a ...  \\\n",
       "546323      4  **Summary**\\n       - Best - I have to start b...   \n",
       "466919      2  Torii @ Lavel, Quecec, Canada, \\u30ab\\u30ca\\u3...   \n",
       "570102      4  WED, MARCH 27, 2013 // 12:00PM-2:00PM \\n      ...   \n",
       "603624      1  Was hier rumsitzt kennt das Angebot, diese bun...   \n",
       "\n",
       "                                                input_ids   \n",
       "614419  [101, 10364, 3393, 8183, 3126, 2139, 1048, 100...  \\\n",
       "546323  [101, 1008, 1008, 12654, 1008, 1008, 1032, 105...   \n",
       "466919  [101, 23413, 2072, 1030, 2474, 15985, 1010, 10...   \n",
       "570102  [101, 21981, 1010, 2233, 2676, 1010, 2286, 101...   \n",
       "603624  [101, 2001, 7632, 2121, 19379, 28032, 2480, 21...   \n",
       "\n",
       "                                           attention_mask   \n",
       "614419  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \\\n",
       "546323  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "466919  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "570102  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "603624  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "        input_ids_token_length  \n",
       "614419                    2344  \n",
       "546323                    2045  \n",
       "466919                    1966  \n",
       "570102                    1903  \n",
       "603624                    1896  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"input_ids_token_length\"] > 512].sort_values(by=\"input_ids_token_length\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04655846153846154"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"input_ids_token_length\"] > 512].shape[0] / train_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:  \n",
    " \n",
    " Less than 5% of the reviews are longer than 512 tokens (which is the maximum length of the input for the DistilBERT model) meaning they will be truncated and we will lose information. This isn't ideal because we want to be able to classify the sentiment of the entire review, not just the first 512 tokens. \n",
    "\n",
    "For our use case, it seems reasonable (intuitively) that our model can assess the sentiment of a review based on the first 512 tokens. This analysis is still useful as it gives us a quantitative measure of our information loss by using Distilbert."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to make it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-2403bacf86757b14.arrow and /Users/d/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-b05e24212690dea3.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04dd1736a10468a8417330063ba7481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84ccad438b248878d0bb6e7bd1ff655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30575689f4294db39d39616e2f8fab40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce8af7e34804830a7825fae026b550f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a321a814d1ce4079a6c40dca37d23fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c62156f2454ea3a9b9f5878d7c7086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17ac249adbd424fb0951d5deaf584a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/d/miniforge3/envs/bert/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabb7189085e4a43b205cbd14b1dd095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eca0b69392d4886a0db29055e3d221a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6207237243652344, 'eval_accuracy': 0.25, 'eval_runtime': 1.6253, 'eval_samples_per_second': 12.305, 'eval_steps_per_second': 1.846, 'epoch': 1.0}\n",
      "{'train_runtime': 32.7459, 'train_samples_per_second': 3.054, 'train_steps_per_second': 0.397, 'train_loss': 1.6440379802997296, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13, training_loss=1.6440379802997296, metrics={'train_runtime': 32.7459, 'train_samples_per_second': 3.054, 'train_steps_per_second': 0.397, 'train_loss': 1.6440379802997296, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. down-sample the dataset so it takes less time to train a quick baseline  model\n",
    "dataset_small = dataset[\"train\"].train_test_split(train_size=100, test_size=20, seed=42, stratify_by_column=\"label\")\n",
    "\n",
    "# 3. Load the tokenizer and define the tokenization function\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# 4. Tokenize our training and test data\n",
    "tokenized_datasets = dataset_small.map(tokenize_function, batched=True)\n",
    "\n",
    "# 5. Load in the pre-trained model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-cased\", num_labels=5)\n",
    "\n",
    "# 6. Define an evaluation metric\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# 7. Set up the Trainer\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", num_train_epochs=3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 8. Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted 5 stars for review: This is a great restaurant!\n",
      "Model predicted 5 stars for review: This was overall a good experience, above average restaurant\n",
      "Model predicted 1 stars for review: This was an alright restaurant\n",
      "Model predicted 1 stars for review: This is a pretty bad restaurant. I might try again but I was disappointed\n",
      "Model predicted 5 stars for review: This is a terrible restaurant!\n"
     ]
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predicted_class_id = logits.argmax().item()\n",
    "    return predicted_class_id\n",
    "\n",
    "review_5stars = \"This is a great restaurant!\"\n",
    "review_4stars = \"This was overall a good experience, above average restaurant\"\n",
    "review_3stars = \"This was an alright restaurant\"\n",
    "review_2stars = \"This is a pretty bad restaurant. I might try again but I was disappointed\"\n",
    "review_1stars = \"This is a terrible restaurant!\"\n",
    "\n",
    "reviews = [review_5stars, review_4stars, review_3stars, review_2stars, review_1stars]\n",
    "\n",
    "for review in reviews:\n",
    "    print(f\"Model predicted {predict(review)+1} stars for review: {review}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcdonalds_chatgpt_review = \"There once was a man with low standards, For McDonald's, he had few demands, But this one store Failed him once more, In a way that was truly grand. The cashier took his friend's order, But ignored him, the selfish border, He waited and waited, Became frustrated, And his patience began to falter. He watched as others were served first, His stomach was starting to thirst, He asked for his meal, The manager did deal, But was rude and left him averse. This man had eaten at McDonald's, For over thirty years, he's no fraud, But this store's service, Had made him nervous, To return, he thought it was odd. He'd rather go to Steak n Shake, Despite their racial mistakes, For at least there he knew, They'd serve him, it's true, And not leave him with a stomach ache.\"\n",
    "\n",
    "predict(review)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
